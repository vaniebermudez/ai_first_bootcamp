{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21944,
     "status": "ok",
     "timestamp": 1732338943867,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "Hi66GDvhZv9K",
    "outputId": "494056e3-7750-4b3b-c509-c121bb71f3ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/swarm.git\n",
      "  Cloning https://github.com/openai/swarm.git to /tmp/pip-req-build-eojsb3s1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/swarm.git /tmp/pip-req-build-eojsb3s1\n",
      "  Resolved https://github.com/openai/swarm.git to commit 9db581cecaacea0d46a933d6453c312b034dbf47\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.33.0 in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (1.54.4)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (8.3.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from swarm==0.1.0) (4.66.6)\n",
      "Collecting pre-commit (from swarm==0.1.0)\n",
      "  Downloading pre_commit-4.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting instructor (from swarm==0.1.0)\n",
      "  Downloading instructor-1.6.4-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.33.0->swarm==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (3.11.2)\n",
      "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (0.16)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (3.1.4)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.33.0->swarm==0.1.0)\n",
      "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (2.23.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (9.0.0)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor->swarm==0.1.0) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->swarm==0.1.0) (2024.8.30)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading identify-2.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->swarm==0.1.0) (6.0.2)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit->swarm==0.1.0)\n",
      "  Downloading virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest->swarm==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor->swarm==0.1.0) (4.0.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.33.0->swarm==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor->swarm==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.33.0->swarm==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor->swarm==0.1.0) (1.5.4)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0) (3.16.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->swarm==0.1.0) (4.3.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->instructor->swarm==0.1.0) (0.1.2)\n",
      "Downloading instructor-1.6.4-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pre_commit-4.0.1-py2.py3-none-any.whl (218 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Downloading identify-2.6.2-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading virtualenv-20.27.1-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: swarm\n",
      "  Building wheel for swarm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for swarm: filename=swarm-0.1.0-py3-none-any.whl size=25999 sha256=130587b6fccf6ba0cf8f08cef19b46ad5c6c303a8cddd3f9e663bc588cdd5732\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_iux_0o/wheels/46/9a/f7/7b8bbb674ae80ef0f62a632706c2c4cdfcf708e4da32e4e256\n",
      "Successfully built swarm\n",
      "Installing collected packages: distlib, virtualenv, nodeenv, jiter, identify, cfgv, pre-commit, instructor, swarm\n",
      "  Attempting uninstall: jiter\n",
      "    Found existing installation: jiter 0.7.1\n",
      "    Uninstalling jiter-0.7.1:\n",
      "      Successfully uninstalled jiter-0.7.1\n",
      "Successfully installed cfgv-3.4.0 distlib-0.3.9 identify-2.6.2 instructor-1.6.4 jiter-0.6.1 nodeenv-1.9.1 pre-commit-4.0.1 swarm-0.1.0 virtualenv-20.27.1\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/swarm.git\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1732339025441,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "bm6-eHNWcf4J"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'swarm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswarm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Swarm, Agent\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'swarm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from swarm import Swarm, Agent\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1732339098819,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "83a2a7QSczHD"
   },
   "outputs": [],
   "source": [
    "api = OpenAI(api_key=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq3wFDZxdQ37"
   },
   "source": [
    "## Initialize Swarm Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1732339239607,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "PToHMPcoc8nz"
   },
   "outputs": [],
   "source": [
    "client = Swarm(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evChW9gZe7M8"
   },
   "source": [
    "## Handoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1732339766687,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "G-ZvzoXvdwdT"
   },
   "outputs": [],
   "source": [
    "def handoff_to_seo_bot():\n",
    "  return seo_bot\n",
    "\n",
    "def handoff_to_content_creator():\n",
    "  return content_creator_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38G7icGne_WC"
   },
   "source": [
    "## Lead Generator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1732341453018,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "6NhRZWmRfC6X"
   },
   "outputs": [],
   "source": [
    "lead_generator_bot = Agent(\n",
    "    name = \"Lead Generator Bot\",\n",
    "    instructions= \"Identify potential audiences and gather data on search trends and competitor\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    functions = [handoff_to_seo_bot]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BEhJL8PfzwV"
   },
   "source": [
    "## SEO Bot Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1732341454593,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "ZVRe4zjCfBQl"
   },
   "outputs": [],
   "source": [
    "seo_bot = Agent(\n",
    "    name=\"SEO Bot\",\n",
    "    instructions=\"Conduct keyword research and optimize content for search engines. Provide SEO insights to improve visibility.\",\n",
    "    model = \"gpt-4o-mini\",\n",
    "    functions=[handoff_to_content_creator],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN-Nbizyf-4M"
   },
   "source": [
    "## Content Creator Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1732341456741,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "Wn10rQsHfund"
   },
   "outputs": [],
   "source": [
    "content_creator_bot = Agent(\n",
    "    name = \"Content Creator Bot\",\n",
    "    instructions = \"Create a marketing content that is engaging and SEO-friendly based on input from other agents.\",\n",
    "    model = \"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 21605,
     "status": "ok",
     "timestamp": 1732341479352,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "pk9NtNIkhN9Q"
   },
   "outputs": [],
   "source": [
    "response = client.run(\n",
    "    agent = lead_generator_bot,\n",
    "    messages = [\n",
    "        {\"role\":\"user\", \"content\": \"I want to create a blog about prompt engineering.\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1732341481317,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "4fNf3pkOhpuf",
    "outputId": "2fea6ff6-41ad-4426-a7e5-73aae28db346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output: ### Title: Mastering the Art of Prompt Engineering: A Comprehensive Guide\n",
      "\n",
      "---\n",
      "\n",
      "#### Introduction\n",
      "\n",
      "In an era dominated by artificial intelligence and machine learning, prompt engineering has emerged as a crucial skill for anyone working with AI language models. Whether you’re a developer, data scientist, or simply an enthusiast, understanding how to craft effective prompts can significantly enhance the quality of AI-generated content. In this blog, we'll delve into the principles of prompt engineering, providing tips and techniques to help you achieve optimal results from AI tools.\n",
      "\n",
      "---\n",
      "\n",
      "#### What is Prompt Engineering?\n",
      "\n",
      "Prompt engineering refers to the process of designing and refining the inputs (or prompts) given to AI models, particularly natural language processing (NLP) systems. These prompts guide the model’s output, influencing the relevance, context, and creativity of the generated content. \n",
      "\n",
      "#### Why is Prompt Engineering Important?\n",
      "\n",
      "1. **Enhanced Output Quality**: A well-crafted prompt can lead to more accurate and contextually appropriate responses from the AI.\n",
      "2. **Creative Applications**: Writers, marketers, and content creators can use prompt engineering to inspire unique ideas and narrative styles.\n",
      "3. **Efficiency**: Effective prompts reduce the iterations needed to get satisfactory responses, saving you time and resources.\n",
      "\n",
      "---\n",
      "\n",
      "#### The Fundamentals of Crafting Effective Prompts\n",
      "\n",
      "1. **Be Specific**: More specific prompts provide clearer instructions to the AI, resulting in targeted outputs. Instead of asking, “Tell me about cars,” try “Explain the benefits of electric vehicles in urban areas.”\n",
      "\n",
      "2. **Use Contextual Language**: Providing background or context can guide the AI to understand better what you’re looking for. For example, instead of submitting a vague question, offer details about the audience or purpose of the request.\n",
      "\n",
      "3. **Experiment with Formats**: Different formats elicit different responses. Try using questions, statements, or even lists to see which format yields the most useful output.\n",
      "\n",
      "4. **Iterate and Refine**: Don’t hesitate to rephrase and refine your prompts. Analyze the outputs you receive to understand what works and what doesn’t.\n",
      "\n",
      "---\n",
      "\n",
      "#### Advanced Techniques in Prompt Engineering\n",
      "\n",
      "- **Role-Playing Prompts**: Ask the AI to assume a specific role, such as “You are a marketing expert. What strategy would you suggest for a new coffee shop opening?”\n",
      "\n",
      "- **Few-Shot Learning**: Provide examples in your prompts. For instance, if you want the AI to generate product descriptions, give a couple of examples first.\n",
      "\n",
      "- **Conditional Instructions**: Incorporate conditional statements to steer outputs under certain criteria, such as “If the topic is technology, respond in a technical tone; otherwise, keep it simple.”\n",
      "\n",
      "---\n",
      "\n",
      "#### Common Pitfalls to Avoid\n",
      "\n",
      "1. **Vagueness**: Avoid open-ended and vague prompts which can lead to generalized and unsatisfactory responses.\n",
      "2. **Overly Complex Prompts**: Complicated prompts can confuse the AI. Keep it simple and clear.\n",
      "3. **Ignoring the Model's Limitations**: Familiarize yourself with the constraints of the AI model you are using to set realistic expectations for the outputs.\n",
      "\n",
      "---\n",
      "\n",
      "#### Conclusion\n",
      "\n",
      "Prompt engineering is more than just a skill: it’s an art form that can unlock the full potential of AI language models. By understanding its principles and employing effective strategies, you can create prompts that lead to exceptional results for a variety of applications, from content creation to data analysis. \n",
      "\n",
      "Don't hesitate to experiment, adapt, and learn through practice. With time and creativity, you'll master prompt engineering, helping you achieve your AI-driven goals more efficiently.\n",
      "\n",
      "---\n",
      "\n",
      "#### Call to Action\n",
      "\n",
      "Curious to explore more about prompt engineering and AI tools? Subscribe to our blog for more insights, tips, and the latest trending topics in the world of artificial intelligence!\n",
      "\n",
      "---\n",
      "\n",
      "### SEO Keywords to Include:\n",
      "\n",
      "- Prompt engineering\n",
      "- Effective prompts for AI\n",
      "- AI language models\n",
      "- Natural language processing\n",
      "- Creating better prompts\n",
      "- AI-generated content\n",
      "\n",
      "---\n",
      "\n",
      "This engaging and informative blog post not only serves to educate readers about prompt engineering but also includes SEO-friendly keywords to increase visibility and ranking on search engine results.\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Output:\", response.messages[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1732341490684,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "xQHz7NuAiZJT",
    "outputId": "54cb85cb-1ef5-41c0-e3be-e318ba2bd546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(response.messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1732341514415,
     "user": {
      "displayName": "Vanessa Althea Bermudez",
      "userId": "00248249844997249383"
     },
     "user_tz": -480
    },
    "id": "vSrXM_qMjB6S",
    "outputId": "6d53380a-15d8-4cb6-afa5-bdbf55adfedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output: {\"assistant\": \"Content Creator Bot\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Output:\", response.messages[-3][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UBz4MyWmZ0y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLLsNxP4F276F0yjPyqg6c",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
